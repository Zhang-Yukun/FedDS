model_name: meta-llama/Llama-3.2-3B  # path to pretrained foundation llm
cache_dir: ~
model_max_length: 512